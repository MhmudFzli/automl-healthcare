{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e353615",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from optuna.samplers import TPESampler\n",
    "import warnings\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.linear_model import Lasso, Ridge, RidgeCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    make_scorer,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    roc_auc_score,\n",
    ")\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from pathlib import Path\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88486e02",
   "metadata": {},
   "source": [
    "### Extract Features from omr.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a15a8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_id = pd.read_csv(\"patients_subject_id.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3341611f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading and aggregating OMR in chunks...\n",
      "Finished reading chunks. Building per-subject summary...\n",
      "Saved summary to: omr_summary.csv\n",
      "Summary shape: (25233, 13)\n"
     ]
    }
   ],
   "source": [
    "# ---------- USER: set these ----------\n",
    "omr_path = Path(\"E:/Chrome Dls/MIMIC_IV_Core/hosp/omr.csv\")   # or \"omr.csv\"\n",
    "pat_set = set(subject_id[\"subject_id\"].values)   # your set of subject_ids (ensure it's a set of ints)\n",
    "chunksize = 500_000             # tune depending on memory\n",
    "out_path = Path(\"omr_summary.csv\")\n",
    "# ------------------------------------\n",
    "\n",
    "if out_path.exists():\n",
    "    omr_summary = pd.read_csv(out_path)\n",
    "else:\n",
    "    # mapping result_name variants -> canonical short name + metadata\n",
    "    NAME_MAP = {\n",
    "        # weight: some rows are \"Weight (Lbs)\" (imperial) and some \"Weight\" (unit unknown)\n",
    "        \"weight (lbs)\": (\"weight_kg\", \"lbs\"),\n",
    "        \"weight\": (\"weight_kg\", None),\n",
    "        # height variants\n",
    "        \"height (inches)\": (\"height_cm\", \"in\"),\n",
    "        \"height\": (\"height_cm\", None),\n",
    "        # BMI variants\n",
    "        \"bmi (kg/m2)\": (\"bmi\", None),\n",
    "        \"bmi\": (\"bmi\", None),\n",
    "        # blood pressure variants (we will split into sys/dia)\n",
    "        \"blood pressure\": (\"bp\", None),\n",
    "        \"blood pressure sitting\": (\"bp\", None),\n",
    "        \"blood pressure standing (1 min)\": (\"bp\", None),\n",
    "        \"blood pressure lying\": (\"bp\", None),\n",
    "        \"blood pressure standing\": (\"bp\", None),\n",
    "        \"blood pressure standing (3 mins)\": (\"bp\", None),\n",
    "        # kidney function\n",
    "        \"egfr\": (\"egfr\", None),\n",
    "    }\n",
    "\n",
    "    # Prepare accumulators: sums & counts per (subject, measure)\n",
    "    sums = {}            # key: (subject_id, measure) -> float sum\n",
    "    counts = {}          # key -> int count\n",
    "\n",
    "    # helper functions\n",
    "    def normalize_name(name):\n",
    "        if not isinstance(name, str):\n",
    "            return None\n",
    "        n = name.strip().lower()\n",
    "        return n\n",
    "\n",
    "    # parse a result_value into numeric(s)\n",
    "    def parse_value_for_measure(measure_key, raw_value):\n",
    "        if pd.isna(raw_value):\n",
    "            return None\n",
    "\n",
    "        v = str(raw_value).strip()\n",
    "\n",
    "        # Blood pressure: look for \"120/80\" or \"120 / 80\" or \"120/80 mmHg\"\n",
    "        if measure_key == \"bp\":\n",
    "            m = re.search(r'(\\d+)\\D+(\\d+)', v)\n",
    "            if m:\n",
    "                sys = pd.to_numeric(m.group(1), errors='coerce')\n",
    "                dia = pd.to_numeric(m.group(2), errors='coerce')\n",
    "                return (sys, dia)\n",
    "            else:\n",
    "                # fallback: look for two numbers\n",
    "                nums = re.findall(r'\\d+', v)\n",
    "                if len(nums) >= 2:\n",
    "                    return (pd.to_numeric(nums[0]), pd.to_numeric(nums[1]))\n",
    "                return None\n",
    "\n",
    "        # For other numeric measures, extract first floating number\n",
    "        m = re.search(r'[-+]?\\d*\\.\\d+|\\d+', v)\n",
    "        if m:\n",
    "            try:\n",
    "                return float(m.group(0))\n",
    "            except:\n",
    "                return None\n",
    "        return None\n",
    "\n",
    "    # conversion helpers\n",
    "    def lbs_to_kg(x): return x * 0.45359237\n",
    "    def inches_to_cm(x): return x * 2.54\n",
    "\n",
    "    # process file in chunks\n",
    "    print(\"Reading and aggregating OMR in chunks...\")\n",
    "    read_kwargs = {\"usecols\": ['subject_id','chartdate','seq_num','result_name','result_value'],\n",
    "                \"chunksize\": chunksize}\n",
    "    if omr_path.suffix == \".gz\":\n",
    "        read_kwargs[\"compression\"] = \"gzip\"\n",
    "\n",
    "    for chunk in pd.read_csv(omr_path, **read_kwargs, low_memory=False):\n",
    "        # filter by subject set early to reduce memory\n",
    "        chunk = chunk[chunk['subject_id'].isin(pat_set)]\n",
    "        if chunk.empty:\n",
    "            continue\n",
    "\n",
    "        # normalize result_name to map\n",
    "        chunk['result_name_norm'] = chunk['result_name'].str.lower().str.strip()\n",
    "\n",
    "        # iterate rows (vectorized attempts are possible but this is robust)\n",
    "        for row in chunk.itertuples(index=False):\n",
    "            subj = row.subject_id\n",
    "            rn = row.result_name_norm\n",
    "            if rn not in NAME_MAP:\n",
    "                continue\n",
    "            measure, unit_hint = NAME_MAP[rn]   # measure: 'weight_kg', 'height_cm', 'bp', etc.\n",
    "            parsed = parse_value_for_measure(measure, row.result_value)\n",
    "            if parsed is None:\n",
    "                continue\n",
    "\n",
    "            if measure == \"bp\":\n",
    "                # parsed is a tuple (sys, dia)\n",
    "                sys_val, dia_val = parsed\n",
    "                if pd.notna(sys_val):\n",
    "                    key = (subj, \"bp_sys\")\n",
    "                    sums[key] = sums.get(key, 0.0) + float(sys_val)\n",
    "                    counts[key] = counts.get(key, 0) + 1\n",
    "                if pd.notna(dia_val):\n",
    "                    key = (subj, \"bp_dia\")\n",
    "                    sums[key] = sums.get(key, 0.0) + float(dia_val)\n",
    "                    counts[key] = counts.get(key, 0) + 1\n",
    "            else:\n",
    "                val = parsed\n",
    "                if val is None or (isinstance(val, float) and np.isnan(val)):\n",
    "                    continue\n",
    "\n",
    "                # convert units if hint given\n",
    "                if measure == \"weight_kg\" and unit_hint == \"lbs\":\n",
    "                    val = lbs_to_kg(val)\n",
    "                if measure == \"height_cm\" and unit_hint == \"in\":\n",
    "                    val = inches_to_cm(val)\n",
    "\n",
    "                key = (subj, measure)\n",
    "                sums[key] = sums.get(key, 0.0) + float(val)\n",
    "                counts[key] = counts.get(key, 0) + 1\n",
    "\n",
    "    print(\"Finished reading chunks. Building per-subject summary...\")\n",
    "\n",
    "    # build rows per subject\n",
    "    subjects = sorted({k[0] for k in counts.keys()})\n",
    "    rows = []\n",
    "    for subj in subjects:\n",
    "        row = {\"subject_id\": subj}\n",
    "        for m in [\"weight_kg\",\"height_cm\",\"bmi\",\"bp_sys\",\"bp_dia\",\"egfr\"]:\n",
    "            key = (subj, m)\n",
    "            s = sums.get(key, 0.0)\n",
    "            c = counts.get(key, 0)\n",
    "            row[f\"{m}_mean\"] = (s / c) if c > 0 else np.nan\n",
    "            row[f\"{m}_count\"] = c\n",
    "        rows.append(row)\n",
    "\n",
    "    omr_summary = pd.DataFrame(rows)\n",
    "\n",
    "    # Optional: if BMI missing but weight & height available, compute BMI = weight_kg / (height_m **2)\n",
    "    mask_bmi_na = omr_summary['bmi_mean'].isna()\n",
    "    have_wt_ht = mask_bmi_na & omr_summary['weight_kg_mean'].notna() & omr_summary['height_cm_mean'].notna()\n",
    "    if have_wt_ht.any():\n",
    "        wt = omr_summary.loc[have_wt_ht, 'weight_kg_mean']\n",
    "        ht_m = omr_summary.loc[have_wt_ht, 'height_cm_mean'] / 100.0\n",
    "        omr_summary.loc[have_wt_ht, 'bmi_mean'] = wt / (ht_m ** 2)\n",
    "\n",
    "    # Save compact file\n",
    "    omr_summary.to_csv(out_path, index=False)\n",
    "    print(\"Saved summary to:\", out_path)\n",
    "    print(\"Summary shape:\", omr_summary.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdcf8c84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>weight_kg_mean</th>\n",
       "      <th>weight_kg_count</th>\n",
       "      <th>height_cm_mean</th>\n",
       "      <th>height_cm_count</th>\n",
       "      <th>bmi_mean</th>\n",
       "      <th>bmi_count</th>\n",
       "      <th>bp_sys_mean</th>\n",
       "      <th>bp_sys_count</th>\n",
       "      <th>bp_dia_mean</th>\n",
       "      <th>bp_dia_count</th>\n",
       "      <th>egfr_mean</th>\n",
       "      <th>egfr_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>42.231264</td>\n",
       "      <td>25</td>\n",
       "      <td>152.40000</td>\n",
       "      <td>2</td>\n",
       "      <td>18.5375</td>\n",
       "      <td>8</td>\n",
       "      <td>106.166667</td>\n",
       "      <td>6</td>\n",
       "      <td>64.666667</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000084</td>\n",
       "      <td>77.110703</td>\n",
       "      <td>1</td>\n",
       "      <td>177.80000</td>\n",
       "      <td>1</td>\n",
       "      <td>24.4000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000117</td>\n",
       "      <td>50.407558</td>\n",
       "      <td>28</td>\n",
       "      <td>163.98875</td>\n",
       "      <td>16</td>\n",
       "      <td>18.5480</td>\n",
       "      <td>25</td>\n",
       "      <td>114.805556</td>\n",
       "      <td>72</td>\n",
       "      <td>71.847222</td>\n",
       "      <td>72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000161</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>126.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>87.500000</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000248</td>\n",
       "      <td>76.203518</td>\n",
       "      <td>1</td>\n",
       "      <td>172.72000</td>\n",
       "      <td>1</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  weight_kg_mean  weight_kg_count  height_cm_mean  \\\n",
       "0    10000032       42.231264               25       152.40000   \n",
       "1    10000084       77.110703                1       177.80000   \n",
       "2    10000117       50.407558               28       163.98875   \n",
       "3    10000161             NaN                0             NaN   \n",
       "4    10000248       76.203518                1       172.72000   \n",
       "\n",
       "   height_cm_count  bmi_mean  bmi_count  bp_sys_mean  bp_sys_count  \\\n",
       "0                2   18.5375          8   106.166667             6   \n",
       "1                1   24.4000          1          NaN             0   \n",
       "2               16   18.5480         25   114.805556            72   \n",
       "3                0       NaN          0   126.500000             2   \n",
       "4                1   25.5000          1          NaN             0   \n",
       "\n",
       "   bp_dia_mean  bp_dia_count  egfr_mean  egfr_count  \n",
       "0    64.666667             6        NaN           0  \n",
       "1          NaN             0        NaN           0  \n",
       "2    71.847222            72        NaN           0  \n",
       "3    87.500000             2        NaN           0  \n",
       "4          NaN             0        NaN           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "omr_summary.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b564ac",
   "metadata": {},
   "source": [
    "# Optional: which patients ain't omr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e50e603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count missing in omr: 11666\n"
     ]
    }
   ],
   "source": [
    "# make sure subject_id is unique in both dfs\n",
    "patients_ids = set(subject_id['subject_id'].unique())\n",
    "omr_ids = set(omr_summary['subject_id'].unique())\n",
    "\n",
    "# set difference\n",
    "missing_in_omr = patients_ids - omr_ids\n",
    "print(\"Count missing in omr:\", len(missing_in_omr))\n",
    "\n",
    "# if you want it as a DataFrame:\n",
    "missing_df = pd.DataFrame(sorted(list(missing_in_omr)), columns=['subject_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "253bf1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject_id  itemid value valueuom\n",
      "0    10002114  224639  71.5       kg\n",
      "1    10002114  226512  64.1       kg\n",
      "2    10002114  224639  64.1       kg\n",
      "3    10002667  226512  87.7       kg\n",
      "4    10002667  224639  89.6       kg\n",
      "Unique patients found in chartevents: 3598\n"
     ]
    }
   ],
   "source": [
    "# Suppose missing_df['subject_id'] is your list of missing patients\n",
    "missing_ids = set(missing_df['subject_id'].unique())\n",
    "\n",
    "# Read only the needed columns from chartevents\n",
    "usecols = ['subject_id', 'itemid', 'value', 'valueuom']\n",
    "chunk_size = 1_000_000  # adjust depending on your RAM\n",
    "\n",
    "results = []\n",
    "\n",
    "for chunk in pd.read_csv(\"E:/Chrome Dls/MIMIC_IV_Core/icu/chartevents.csv\", usecols=usecols, chunksize=chunk_size):\n",
    "    # keep only missing patients\n",
    "    chunk = chunk[chunk['subject_id'].isin(missing_ids)]\n",
    "    \n",
    "    # keep only rows with kg (weight) or Inches (height)\n",
    "    chunk = chunk[chunk['valueuom'].isin(['kg', 'Inches'])]\n",
    "    \n",
    "    results.append(chunk)\n",
    "\n",
    "chartevents_subset = pd.concat(results, ignore_index=True)\n",
    "print(chartevents_subset.head())\n",
    "print(\"Unique patients found in chartevents:\", chartevents_subset['subject_id'].nunique())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
